{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vqc.vqc_circuits import *\n",
    "from cirq.contrib.svg import SVGCircuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 2\n",
    "num_layers = 3\n",
    "\n",
    "uqc = UQC(num_qubits, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"799.7100390625\" height=\"100.0\"><line x1=\"34.7588671875\" x2=\"769.7100390625\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"769.7100390625\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"289.5818359375\" x2=\"289.5818359375\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"539.6459375\" x2=\"539.6459375\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"55.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 1): </text><rect x=\"79.517734375\" y=\"5.0\" width=\"68.5230078125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"113.77923828125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(x0_0)</text><rect x=\"79.517734375\" y=\"55.0\" width=\"68.5230078125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"113.77923828125\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(x0_1)</text><rect x=\"168.0407421875\" y=\"5.0\" width=\"81.54109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"208.8112890625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta0)</text><rect x=\"168.0407421875\" y=\"55.0\" width=\"81.54109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"208.8112890625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta1)</text><circle cx=\"289.5818359375\" cy=\"25.0\" r=\"10.0\" /><circle cx=\"289.5818359375\" cy=\"75.0\" r=\"10.0\" /><rect x=\"329.58183593749993\" y=\"5.0\" width=\"68.5230078125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"363.84333984374996\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(x1_0)</text><rect x=\"329.58183593749993\" y=\"55.0\" width=\"68.5230078125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"363.84333984374996\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(x1_1)</text><rect x=\"418.10484375\" y=\"5.0\" width=\"81.54109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"458.87539062499997\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta2)</text><rect x=\"418.10484375\" y=\"55.0\" width=\"81.54109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"458.87539062499997\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta3)</text><circle cx=\"539.6459375\" cy=\"25.0\" r=\"10.0\" /><circle cx=\"539.6459375\" cy=\"75.0\" r=\"10.0\" /><rect x=\"579.6459375\" y=\"5.0\" width=\"68.5230078125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"613.90744140625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(x2_0)</text><rect x=\"579.6459375\" y=\"55.0\" width=\"68.5230078125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"613.90744140625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(x2_1)</text><rect x=\"668.1689453125\" y=\"5.0\" width=\"81.54109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"708.9394921875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta4)</text><rect x=\"668.1689453125\" y=\"55.0\" width=\"81.54109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"708.9394921875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta5)</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7f7d1ea113a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVGCircuit(uqc.circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[theta0, theta1, theta2, theta3, theta4, theta5]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uqc.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_symbols, input_symbols = uqc.parameters, uqc.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 15:14:35.627272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-30 15:14:35.669380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-30 15:14:35.669455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-30 15:14:35.670867: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 15:14:35.674628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-30 15:14:35.674716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-30 15:14:35.674762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-30 15:14:37.214281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-30 15:14:37.214369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-30 15:14:37.214379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-30 15:14:37.214429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-30 15:14:37.214473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4585 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "symbols = [str(symb) for symb in theta_symbols + input_symbols]\n",
    "indices = tf.constant([symbols.index(a) for a in sorted(symbols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thetas <tf.Variable 'Variable:0' shape=(1, 6) dtype=float32, numpy=\n",
      "array([[1.0045788 , 2.1837795 , 2.6492646 , 0.9868766 , 0.32571512,\n",
      "        0.25387233]], dtype=float32)>\n",
      "W <tf.Variable 'Variable:0' shape=(3, 2, 4) dtype=float32, numpy=\n",
      "array([[[ 0.40569243, -0.62483126, -0.18749611,  0.81928974],\n",
      "        [ 1.1096076 , -2.0239332 , -1.2835801 , -0.04816956]],\n",
      "\n",
      "       [[ 0.5339693 ,  0.7501102 ,  1.0311714 ,  0.7866034 ],\n",
      "        [-1.9672835 , -0.58688366,  0.90287834, -1.1822499 ]],\n",
      "\n",
      "       [[ 0.51129156, -0.35648385,  0.70196736,  0.8480966 ],\n",
      "        [-1.5714412 ,  1.2228214 , -1.2697752 ,  0.54176885]]],\n",
      "      dtype=float32)>\n",
      "B <tf.Variable 'Variable:0' shape=(3, 2) dtype=float32, numpy=\n",
      "array([[-0.8123364 ,  0.32774994],\n",
      "       [-1.2374929 ,  1.0792578 ],\n",
      "       [-1.240873  ,  1.0454992 ]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "theta_init = tf.random_uniform_initializer(minval=0.0, maxval=np.pi)\n",
    "theta = tf.Variable(initial_value=theta_init(shape=(1, len(theta_symbols)), dtype=\"float32\"))\n",
    "print(\"Thetas\", theta)\n",
    "\n",
    "w_init = tf.random_normal_initializer(mean=0.0, stddev=1)\n",
    "w = tf.Variable(initial_value = w_init(shape = (num_layers,num_qubits,state_size), dtype = \"float32\"))\n",
    "print(\"W\", w)\n",
    "        \n",
    "b_init = tf.random_normal_initializer(mean=0.0, stddev=1)\n",
    "#b_init = tf.random_normal_initializer(mean=0.0, stddev=0.1)\n",
    "b = tf.Variable(initial_value = b_init(shape = (num_layers,num_qubits), dtype = \"float32\"))\n",
    "print(\"B\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiled_up_thetas = tf.tile(tf.multiply(theta,2), multiples=[batch_dim, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.77486265, 0.63901734, 0.57549345, 0.45996523]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tf.random.uniform(shape = (batch_dim, state_size), minval = 0, maxval = 1)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 4), dtype=float32, numpy=\n",
       "array([[[[0.77486265, 0.63901734, 0.57549345, 0.45996523]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_inputs = tf.reshape(inputs, (batch_dim, 1, 1, state_size))\n",
    "reshaped_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 2, 4), dtype=float32, numpy=\n",
       "array([[[[0.77486265, 0.63901734, 0.57549345, 0.45996523],\n",
       "         [0.77486265, 0.63901734, 0.57549345, 0.45996523]],\n",
       "\n",
       "        [[0.77486265, 0.63901734, 0.57549345, 0.45996523],\n",
       "         [0.77486265, 0.63901734, 0.57549345, 0.45996523]],\n",
       "\n",
       "        [[0.77486265, 0.63901734, 0.57549345, 0.45996523],\n",
       "         [0.77486265, 0.63901734, 0.57549345, 0.45996523]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiled_inputs = tf.tile(reshaped_inputs, multiples = [1,num_layers, num_qubits,1])\n",
    "tiled_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 2), dtype=float32, numpy=\n",
       "array([[[ 0.3680398, -2.3887663],\n",
       "        [ 3.696658 , -3.8471932],\n",
       "        [ 1.924908 , -1.8355987]]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_times_weights = tf.reduce_sum(tf.multiply(w,2) * reshaped_inputs, axis = -1, keepdims = False)\n",
    "inputs_times_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 2), dtype=float32, numpy=\n",
       "array([[[-0.8123364 ,  0.32774994],\n",
       "        [-1.2374929 ,  1.0792578 ],\n",
       "        [-1.240873  ,  1.0454992 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiled_up_bias = tf.reshape(tf.tile(b, multiples = [batch_dim, 1]), (batch_dim, num_layers, num_qubits))\n",
    "tiled_up_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 2), dtype=float32, numpy=\n",
       "array([[[-1.256633 , -1.7332664],\n",
       "        [ 1.221672 , -1.6886775],\n",
       "        [-0.5568379,  0.2553997]]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_times_weights_plus_b = inputs_times_weights + tf.multiply(tiled_up_bias,2)\n",
    "inputs_times_weights_plus_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
       "array([[-1.256633 , -1.7332664,  1.221672 , -1.6886775, -0.5568379,\n",
       "         0.2553997]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_inputs_times_weights_plus_b = tf.reshape(inputs_times_weights_plus_b, (batch_dim, num_layers * num_qubits))\n",
    "reshaped_inputs_times_weights_plus_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uqc.num_qubits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
